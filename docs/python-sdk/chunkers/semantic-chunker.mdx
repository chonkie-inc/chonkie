---
title: 'Semantic Chunker'
description: 'Split text into chunks based on semantic similarity with advanced features'
icon: 'vector-square'
---

The `SemanticChunker` splits text into chunks based on semantic similarity, ensuring that related content stays together in the same chunk. This chunker now includes advanced features like Savitzky-Golay filtering for smoother boundary detection and skip-window merging for connecting related content that may not be consecutive. This chunker is inspired by the work of [Greg Kamradt](https://github.com/gkamradt).

## API Reference
To use the `SemanticChunker` via the API, check out the [API reference documentation](../../api-reference/semantic-chunker).

## Installation

SemanticChunker requires additional dependencies for semantic capabilities. You can install it with:

```bash
pip install "chonkie[semantic]"
```

<Info>For installation instructions, see the [Installation Guide](/getting-started/installation).</Info>

## Initialization

```python
from chonkie import SemanticChunker

# Basic initialization with default parameters
chunker = SemanticChunker(
    embedding_model="minishlab/potion-base-8M",  # Default model
    threshold=0.8,                               # Similarity threshold (0-1)
    chunk_size=2048,                             # Maximum tokens per chunk
    similarity_window=3,                         # Window for similarity calculation
    skip_window=0                                # Skip-and-merge window (0=disabled)
)

# With skip-and-merge enabled (similar to legacy SDPM behavior)
chunker = SemanticChunker(
    embedding_model="minishlab/potion-base-8M",
    threshold=0.7,
    chunk_size=2048,
    skip_window=1  # Enable merging of similar non-consecutive groups
)
```

## Parameters

<ParamField
    path="embedding_model"
    type="Union[str, BaseEmbeddings]"
    default="minishlab/potion-base-8M"
>
    Model identifier or embedding model instance
</ParamField>

<ParamField
    path="threshold"
    type="float"
    default="0.8"
>
    Similarity threshold for grouping sentences (0-1). Lower values create larger groups.
</ParamField>

<ParamField
    path="chunk_size"
    type="int"
    default="2048"
>
    Maximum tokens per chunk
</ParamField>

<ParamField
    path="similarity_window"
    type="int"
    default="3"
>
    Number of sentences to consider for similarity calculation
</ParamField>

<ParamField
    path="min_sentences_per_chunk"
    type="int"
    default="1"
>
    Minimum number of sentences per chunk
</ParamField>

<ParamField
    path="min_characters_per_sentence"
    type="int"
    default="24"
>
    Minimum number of characters per sentence
</ParamField>

<ParamField
    path="skip_window"
    type="int"
    default="0"
>
    Number of groups to skip when looking for similar content to merge.
    - `0` (default): No skip-and-merge, uses standard semantic grouping
    - `1` or higher: Enables merging of semantically similar groups within the skip window
    
    This feature allows the chunker to connect related content that may not be consecutive in the text.
</ParamField>

<ParamField
    path="filter_window"
    type="int"
    default="5"
>
    Window length for the Savitzky-Golay filter used in boundary detection
</ParamField>

<ParamField
    path="filter_polyorder"
    type="int"
    default="3"
>
    Polynomial order for the Savitzky-Golay filter
</ParamField>

<ParamField
    path="filter_tolerance"
    type="float"
    default="0.2"
>
    Tolerance for the Savitzky-Golay filter boundary detection
</ParamField>

<ParamField
    path="delim"
    type="Union[str, List[str]]"
    default='[". ", "! ", "? ", "\n"]'
>
    Delimiters to split sentences on
</ParamField>

<ParamField
    path="include_delim"
    type='Optional[Literal["prev", "next"]]'
    default="prev"
>
    Include delimiters in the chunk text. Specify whether to include with the previous or next sentence.
</ParamField>


## Usage

### Basic Semantic Chunking

```python
from chonkie import SemanticChunker

text = """First paragraph about a specific topic.
Second paragraph continuing the same topic.
Third paragraph switching to a different topic.
Fourth paragraph expanding on the new topic."""

# Standard semantic chunking
chunker = SemanticChunker(
    embedding_model="minishlab/potion-base-8M",
    threshold=0.7,
    chunk_size=512
)

chunks = chunker.chunk(text)

for chunk in chunks:
    print(f"Chunk text: {chunk.text}")
    print(f"Token count: {chunk.token_count}")
```

### With Skip-Window Merging

```python
# Enable skip-window for merging related non-consecutive content
chunker = SemanticChunker(
    embedding_model="minishlab/potion-base-8M",
    threshold=0.6,
    chunk_size=512,
    skip_window=2  # Look up to 2 groups ahead for similar content
)

text = """The neural network processes input data through layers.
Stock market showed volatility today.
Training data is essential for model performance.
Economic indicators suggest growth.
GPUs accelerate neural network computations significantly.
Federal reserve announced new policies."""

chunks = chunker.chunk(text)
# Related AI content will be grouped together despite being separated
```

### Batch Chunking

```python
texts = [
    "First document about topic A...",
    "Second document about topic B..."
]
batch_chunks = chunker.chunk_batch(texts)

for doc_chunks in batch_chunks:
    for chunk in doc_chunks:
        print(f"Chunk: {chunk.text}")
```

## Advanced Features

### Savitzky-Golay Filtering

The SemanticChunker uses Savitzky-Golay filtering for smoother boundary detection in similarity curves. This reduces noise in the semantic similarity signal and provides more stable chunk boundaries.

### Skip-Window Merging

When `skip_window > 0`, the chunker can merge semantically similar groups that are not consecutive. This is useful for:
- Documents with alternating topics
- Content with recurring themes
- Technical documents with distributed related sections

## Supported Embeddings

SemanticChunker supports multiple embedding providers through Chonkie's embedding system. See the [Embeddings Overview](/embeddings/overview) for more information.

## Return Type

SemanticChunker returns `Chunk` objects:

```python
@dataclass
class Chunk:
    text: str
    start_index: int
    end_index: int
    token_count: int
```

## Legacy Versions

<Note>
The original SemanticChunker (pre-v1.2.0) with different parameter names and behavior is available in the legacy module:

```python
from chonkie.legacy import SemanticChunker as LegacySemanticChunker

# Uses old parameter names and behavior
chunker = LegacySemanticChunker(
    mode="window",
    min_sentences=1,
    min_chunk_size=2,
    threshold_step=0.01
)
```

For the SDPM (Semantic Double-Pass Merging) functionality, you can either:
1. Use the new SemanticChunker with `skip_window > 0` (recommended)
2. Use the legacy SDPMChunker (see [SDPM Chunker documentation](./sdpm-chunker))
</Note>