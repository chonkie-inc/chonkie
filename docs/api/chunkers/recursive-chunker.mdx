---
title: "Recursive Chunker"
api: "POST /v1/chunk/recursive"
description: "Recursively split text using multiple delimiters for natural chunks"
---

The Recursive Chunker splits text by trying multiple delimiters in order (paragraphs, sentences, words) to create natural, coherent chunks.

## Examples

### Text Input

<CodeGroup>

```python Python
from chonkie.cloud import RecursiveChunker

chunker = RecursiveChunker(
    chunk_size=512,
    recipe="markdown"
)

text = "Your text here..."
chunks = chunker.chunk(text)
```

```javascript JavaScript
import { RecursiveChunker } from "@chonkiejs/cloud";

const chunker = new RecursiveChunker({
  chunkSize: 512,
  recipe: "markdown"
});

const text = "Your text here...";
const chunks = await chunker.chunk({ text });
```

```bash cURL
curl -X POST https://api.chonkie.ai/v1/chunk/recursive \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Your text here...",
    "chunk_size": 512,
  }'
```

</CodeGroup>

### File Input

<CodeGroup>

```python Python
from chonkie.cloud import RecursiveChunker

chunker = RecursiveChunker(
    chunk_size=512,
    recipe="markdown"
)

# Chunk from file
with open("document.txt", "rb") as f:
    chunks = chunker.chunk(file=f)
```

```javascript JavaScript
import { RecursiveChunker } from "@chonkiejs/cloud";

const chunker = new RecursiveChunker({
  chunkSize: 512,
  recipe: "markdown"
});

// Chunk from file path (Node.js)
const chunks = await chunker.chunk({ filepath: './document.txt' });
```

```bash cURL
# Step 1: Upload the file
curl -X POST https://api.chonkie.ai/v1/files \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -F "file=@document.txt"

# Returns: {"name": "document.txt", "size": "1024"}

# Step 2: Chunk the uploaded file
curl -X POST https://api.chonkie.ai/v1/chunk/recursive \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "file": {
      "type": "document",
      "content": "document.txt"
    },
    "chunk_size": 512,
    "recipe": "markdown"
  }'
```

</CodeGroup>

## Request

#### Parameters

<ParamField path="text" type="string | string[]">
  The text to chunk. Can be a single string or an array of strings for batch processing. Either `text` or `file` is required.
</ParamField>

<ParamField path="file" type="file">
  File to chunk. Use multipart/form-data encoding. Either `text` or `file` is required.
</ParamField>

<ParamField path="tokenizer" type="string" default="gpt2">
  Tokenizer to use for counting tokens.
</ParamField>

<ParamField path="chunk_size" type="integer" default="512">
  Maximum number of tokens per chunk.
</ParamField>

<ParamField path="min_characters_per_chunk" type="integer" default="0">
  The minimum number of characters a chunk should have.
</ParamField>

<ParamField path="recipe" type="string" default="default">
  Recursive rules recipe to follow. See all recipes on our [Hugging Face repo](https://huggingface.co/datasets/chonkie-ai/recipes)
</ParamField>

<ParamField path="lang" type="string" default="en">
  Language of the document to chunk
</ParamField>


## Response

#### Returns

Array of `Chunk` objects, each containing:

<ResponseField name="text" type="string">
  The chunk text content.
</ResponseField>

<ResponseField name="start_index" type="integer">
  Starting character position in the original text.
</ResponseField>

<ResponseField name="end_index" type="integer">
  Ending character position in the original text.
</ResponseField>

<ResponseField name="token_count" type="integer">
  Number of tokens in the chunk.
</ResponseField>
